{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ssd300_vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mssd300_vgg16\u001b[49m(pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m model.eval()\n",
      "\u001b[31mNameError\u001b[39m: name 'ssd300_vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "model = ssd300_vgg16(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', ...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose({\n",
    "        transforms.Resize(300),\n",
    "        transforms.ToTensor(),\n",
    "    })\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    return image, image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference and drawing bounding boxes\n",
    "def detect_objects(image_path):\n",
    "    image, image_tensor = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "    # extract bounding boxes, labels, and scores\n",
    "    boxes = predictions[0]['boxes']\n",
    "    labels = predictions[0]['labels']\n",
    "    scores = predictions[0]['scores']\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.5:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "            draw.text((x1, y1 - 10), f\"{COCO_CLASSES[label]}: {score:.2f}\", fill=\"black\")\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to identify Ms Kasey on the Severed floor of Lumen.\n",
    "\n",
    "![mskasey](mskasey.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_objects(\"mskasey.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our bounding box with person labelled\n",
    "\n",
    "![mskasey found](mskasey_found.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model to onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/ops/boxes.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/ops/boxes.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/models/detection/transform.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
      "/Users/jakehenderson/nocuments/code/projects/ml-daily/.venv/lib/python3.13/site-packages/torchvision/models/detection/transform.py:309: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 300, 300)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"mobilenetv2_ssd.onnx\",\n",
    "    opset_version=11,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"boxes\", \"labels\", \"scores\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model size (MB): 136.28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "onnx_model_path = \"mobilenetv2_ssd.onnx\"\n",
    "# report file size in MB\n",
    "file_size = os.path.getsize(onnx_model_path) / (1024 * 1024)\n",
    "print(f\"ONNX model size (MB): {file_size:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check ram usage when loaded in ONNX runtime\n",
    "import onnxruntime\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage after loading: 737.55 MB\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "#get memory usage\n",
    "process = psutil.Process()\n",
    "memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "print(f\"RAM Usage after loading: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
